# 消息队列

消息队列看作是一个存放消息的容器，当我们需要使用消息的时候，直接从容器中取出消息供自己使用即可。由于队列 Queue 是一种先进先出的数据结构，所以消费消息时也是按照顺序来消费的。

参与消息传递的双方称为 **生产者** 和 **消费者** ，生产者负责发送消息，消费者负责处理消息。

![发布/订阅（Pub/Sub）模型](https://javaguide.cn/assets/message-queue-pub-sub-model-nGMeokOu.png)

**中间件就是一类为应用软件服务的软件，应用软件是为用户服务的，用户不会接触或者使用到中间件。**除了消息队列之外，常见的中间件还有 RPC 框架、分布式组件、HTTP 服务器、任务调度框架、配置中心、数据库层的分库分表工具和数据迁移工具等等。

使用消息队列能为我们的系统带来下面三点好处：

1. **通过异步处理提高系统性能（减少响应所需时间）**
2. **削峰/限流**
3. **降低系统耦合性。**

![image-20240320222251001](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240320222251001.png)

### 削峰、限流

**先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。**

![image-20240320222410110](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240320222410110.png)

降低系统耦合性

消息队列**用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。** 从上图可以看到**消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合**，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。**对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计**。

```
不要认为消息队列只能利用发布-订阅模式工作，只不过在解耦这个特定业务环境下是使用发布-订阅模式的。除了发布-订阅模式，还有点对点订阅模式（一个消息只有一个消费者），我们比较常用的是发布-订阅模式。另外，这两种消息模型是 JMS 提供的，AMQP 协议还提供了另外 5 种消息模型
```

实现分布式事务：RocketMQ、 Kafka、Pulsar、QMQ 都提供了事务相关的功能。事务允许事件流应用将消费，处理，生产消息整个过程定义为一个原子操作。

**使用消息队列带来的问题：**

- **系统可用性降低：** 系统可用性在某种程度上降低，在加入 MQ 之前，不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后需要去考虑
- **系统复杂性提高：** 加入 MQ 之后，需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！
- **一致性问题：**消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息这样就会导致数据不一致的情况了

### 一、JMS和AMQP

#### 1.1基础概念

JMS（JAVA Message Service,java 消息服务）是 Java 的消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。**JMS（JAVA Message Service，Java 消息服务）API 是一个消息服务的标准或者说是规范**，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。

定义了五种不同的消息正文格式以及调用的消息类型，允许你发送并接收以一些不同形式的数据：

- `StreamMessage：Java` 原始值的数据流
- `MapMessage`：一套名称-值对
- `TextMessage`：一个字符串对象
- `ObjectMessage`：一个序列化的 Java 对象
- `BytesMessage`：一个字节的数据流

ActiveMQ（已被淘汰） 就是基于 JMS 规范实现的。

#### 1.2 JMS两种消息模型

用**队列（Queue）\**作为消息通信载体；满足\**生产者与消费者模式**，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。【P2P点到点模型】

![队列模型](https://javaguide.cn/assets/message-queue-queue-model-bdkctLKs.png)

发布订阅模型（Pub/Sub） 使用**主题（Topic）\**作为消息通信载体，类似于\**广播模式**；发布者发布一条消息，该消息通过主题传递给所有的订阅者。

![发布/订阅（Pub/Sub）模型](https://javaguide.cn/assets/message-queue-pub-sub-model-nGMeokOu.png)

#### 1.3 AMQP是什么

AMQP，即 Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准 **高级消息队列协议**（二进制应用层协议），是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。

**RabbitMQ 就是基于 AMQP 协议实现的**

![image-20240321214454695](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240321214454695.png)

- AMQP 为消息定义了线路层（wire-level protocol）的协议，而 JMS 所定义的是 API 规范。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而 AMQP 天然具有跨平台、跨语言特性。
- JMS 支持 `TextMessage`、`MapMessage` 等复杂的消息类型；而 AMQP 仅支持 `byte[]` 消息类型（复杂的类型可序列化后发送）。
- 由于 Exchange 提供的路由算法，AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。

#### 1.4 RPC和消息队列的区别

- 用途：RPC主要用来解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过RPC可以调用远程计算机上的某个服务的方法。消息队列主要用来降低系统的耦合度、实现任务异步、有效进行流量削峰。
- 通信方式：RPC是双向直接网络通训，消息队列则是单向引入中间载体的网络通讯。
- 架构：消息队列需要把消息存储起来，RPC没要求。
- 请求处理的时效性：通过RPC发出的调用一般会立即被处理，存放在消息队列中的消息不一定立即被处理。

### 二、分布式消息队列的技术选型

Kafka:分布式流式处理平台，早期被用来用于处理海量的日志，后面才慢慢发展成了一款功能全面的高性能消息队列。

RocketMQ:阿里开源的一款云原生“消息、事件、流”实时数据处理平台，借鉴了 Kafka，已经成为 Apache 顶级项目。

RabbitMQ:采用 Erlang 语言实现 AMQP(Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。

Pulsar:集消息、存储、轻量化函数式计算为一体，采用计算与存储分离架构设计，支持多租户、持久化存储、多机房跨区域数据复制，具有强一致性、高吞吐、低延时及高可扩展性等流数据存储特性，被看作是云原生时代实时消息流传输、存储和计算最佳解决方案。

#### 2.1 Kafka

Kafka 是一个分布式系统，由通过高性能TCP网络协议进行通信的服务器和客户端组成，可以部署在本地和云环境中的裸机硬件、虚拟机和容器上。

- **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
- **容错的持久方式存储记录消息流**：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。
- **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

#### 2.2 RocketMQ

Apache RocketMQ 自诞生以来，因其架构简单、业务功能丰富、具备极强可扩展性等特点被众多企业开发者以及云厂商广泛采用。历经十余年的大规模场景打磨，RocketMQ 已经成为业内共识的金融级可靠业务消息首选方案，被广泛应用于互联网、大数据、移动互联网、物联网等领域的业务场景。

核心特性：

- 云原生：无限弹性扩缩，K8S友好
- 高吞吐：万亿级吞吐保证，同时满足微服务与大数据场景
- 流处理：提供轻量、高扩展、高性能和丰富功能的流计算引擎
- 金融级：稳定性，广泛用于交易核心链路
- 架构极简：零外部依赖，Shared-nothing架构
- 生态友好：无缝对接微服务、实时计算、数据湖等周边生态

#### 2.3 RabbitMQ

RabbitMQ 的具体特点可以概括为以下几点:

**可靠性**：RabbitMQ 使用一些机制来保证消息的可靠性，如持久化、传输确认。

**灵活的路由：**在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能，RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起，也可以通过插件机制来实现自己的交换器。这个后面会在我们讲 RabbitMQ 核心概念的时候详细介绍到。

**扩展性：** 多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态地扩展集群中节点。

**高可用性：**队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。

**支持多种协议：**RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP、MQTT 等多种消息中间件协议。

**多语言客户端：** RabbitMQ 几乎支持所有常用语言，比如 Java、Python、Ruby、PHP、C#、JavaScript 等。

**易用的管理界面：** RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集群中的节点等。在安装 RabbitMQ 的时候会介绍到，安装好 RabbitMQ 就自带管理界面。

**插件机制：**RabbitMQ 提供了许多插件，以实现从多方面进行扩展，当然也可以编写自己的插件。感觉这个有点类似 Dubbo 的 SPI 机制

#### 2.4  Pulsar

Pulsar 的关键特性如下（摘自官网）：

- 是下一代云原生分布式消息流平台。
- Pulsar 的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息复制。
- 极低的发布延迟和端到端延迟。
- 可无缝扩展到超过一百万个 topic。
- 简单的客户端 API，支持 Java、Go、Python 和 C++。
- 主题的多种订阅模式（独占、共享和故障转移）。
- 通过 Apache BookKeeper 提供的持久化消息存储机制保证消息传递 。
- 由轻量级的 serverless 计算框架 Pulsar Functions 实现流原生的数据处理。
- 基于 Pulsar Functions 的 serverless connector 框架 Pulsar IO 使得数据更易移入、移出 Apache Pulsar。
- 分层式存储可在数据陈旧时，将数据从热存储卸载到冷/长期存储（如 S3、GCS）中。

**总结：**

- RabbitMQ 在吞吐量方面虽然稍逊于 Kafka、RocketMQ 和 Pulsar，但是由于它基于 Erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。但是也因为 RabbitMQ 基于 Erlang 开发，所以国内很少有公司有实力做 Erlang 源码级别的研究和定制。如果业务场景对并发量要求不是太高（十万级、百万级），那这几种消息队列中，RabbitMQ 或许是你的首选。
- RocketMQ 和 Pulsar 支持强一致性，对消息一致性要求比较高的场景可以使用。
- RocketMQ 阿里出品，Java 系开源项目，源代码我们可以直接阅读，然后可以定制自己公司的 MQ，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。
- Kafka 的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 Kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。Kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

### 三、Kafka常见问题总结

#### 3.1基础

主要有两大应用场景：

1. **消息队列**：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。
2. **数据处理：** 构建实时的流数据处理程序来转换或处理数据流。

 Kafka 相比其他消息队列主要的优势如下：

1. **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

​    **3.流式处理平台**：在消息发布的时候进行处理，kafka提供了一个完整的流式处        理类库。

#### 3.2Kafka的核心概念

- **Producer(生产者)**：产生消息的一方
- **Consumer(消费者)**：消费信息的一方
- **Broker(代理)：**可以看作是一个独立的kafka实例。【多个kafka Broker组成一个Kafka Cluster】
- **Topic(主题)**：Producer将消息发送到特定的主题，Consumer通过订阅特定的Topic来消费信息。
- **Partition(分区)：**Partition属于Topic的一部分。一个Topic可以有多个Partition，并且同一个Topic下的Partition可以分布在不同的Broker上，也就说明一个Topic可以横跨多个Broker。

![image-20240401202557554](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401202557554.png)

#### 3.3 Kafka 的多副本机制

kafka为分区引入了多副本（Replica)机制。分区（Partition）中的多个副本之间会有一个leader，其他副本成为follower。发送的消息会被发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步。

【生产者和消费者只与 leader 副本交互。可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。】

**多分区、多副本的好处**：

1.kafka通过给特定Topic 指定多个Partition，而各个Partition可以分布在不同的Broker上，能提供较好的并发能力（负载均衡）

2.Partition可以指定对应的Replica数，可以极大地提高消息存储的安全性，提高容灾能力，但会增加存储空间。

#### 3.4 Zookeeper 和 Kafka

Zookeeper主要为Kafka提供数据的管理功能。

1.**Broker注册**：在Zookeeper上会有一个专门用来进**行Broker服务器列表记录**的节点。每个Broker在启动时，都会到Zookeeper上进行注册，即到/brokers/ids下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去。

2.**Topic 注册**：在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1

3.**负载均衡**：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

【在 Kafka 2.8 之前，Kafka 最被大家诟病的就是其重度依赖于 Zookeeper。在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构】

#### 3.5 Kafka消费顺序、消息丢失和重复消费

**1.Kafka是如何保证消息的消费顺序：**

- 1个Topic只对应一个Partition
- (推荐)发送消息的时候指定key/Partition

每次添加消息到Partition（分区）的时候都会采用尾加法，Kafka只保证Partition（分区）中的消息有序。消息在被追加到Partition（分区）的时候都会分配一个特定的偏移量（offset）Kafka通过偏移量（offset）来保证消息在分区内的顺序性。

![image-20240401222526696](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240401222526696.png)

**2.Kafka是如何保证消息不丢失：**

产生丢失的情况：生产者(Producer) 调用`send`方法发送消息之后，消息可能因为网络问题并没有发送过去。

【消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性】

- **手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。**
- 设置 **acks = all**。acks 是 Kafka 生产者(Producer) 很重要的一个参数。

**3.Kafka是如何保证消息不重复消费：**

重复消费的原因：

- 服务端侧已经消费的数据没有成功提交 offset（根本原因）。
- Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。

解决方法：

1.消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。

2.将 **`enable.auto.commit`** 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：**什么时候提交 offset 合适？**

- 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
- 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底

#### 3.6 Kafka重试机制

1.即使某个消息消费异常，Kafka 消费者仍然能够继续消费后续的消息，不会一直卡在当前消息，保证了业务的正常进行。

2.Kafka 消费者在默认配置下会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败。

**3.重试失败后的数据如何处理**：

**死信队列（Dead Letter Queue，简称 DLQ）** 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被"丢弃"或"死亡"的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。

`@RetryableTopic` 是 Spring Kafka 中的一个注解,它用于配置某个 Topic 支持消息重试，更推荐使用这个注解来完成重试。

当达到最大重试次数后，如果仍然无法成功处理消息，消息会被发送到对应的死信队列中。对于死信队列的处理，既可以用 `@DltHandler` 处理，也可以使用 `@KafkaListener` 重新消费。

### 四、RocketMQ

**消息队列的作用：异步、解耦、削峰**

#### 1、RocketMQ基础

RocketMQ是一个队列模型的消息中间件，具有**高性能、高可靠、高实时、分布式**的特点，是采用java语言开发的分布式的消息系统。

**队列模型：**一个队列

![image-20240402211959538](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402211959538.png)

**主题模型：**在主题模型中，消息的生产者称为**发布者（Publisher**),消息的消费者称为**订阅者（Subscriber)**,存放消息的容器称为**主题（Topic)**

其中，发布者将消息发送到指定主题中，订阅者需要**提前订阅主题**才能接受特定主题的消息。

![image-20240402211950920](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402211950920.png)

**RocketMQ中的消息模型**：

- **Producer Group生产者组：**代表某一类的生产者
- **Consumer Group 消费者组：**代表某一类的消费者
- **Topic主题：**代表一类消息

![image-20240402212243242](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402212243242.png)

图中生产者组中的生产者会向主题发送消息，而**主题中存在多个队列**，生产者每次生产消息之后是指定主题中的某个队列发送消息的。每个主题中都有好多个队列（分布在不同的Broker中，如果是集群的话，Broker又分布在不同的服务器中），集群消费模式下，一个消费者集群

多台机器共同消费一个 `topic` 的多个队列，**一个队列只会被一个消费者消费**。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。就像上图中 `Consumer1` 和 `Consumer2` 分别对应着两个队列，而 `Consumer3` 是没有队列对应的，所以一般来讲要控制 **消费者组中的消费者个数和主题中队列个数相同** 。

【**一个Topic分布在多个Broker上，一个Broker可以配置多个Topic，他们之间是多对多的关系**。如果某个Topic消息量很大，应该给它多配置几个队列，并且**尽量多分布在不同Broker上，以减轻某个Broker的压力**。Topic消息量都比较均匀的情况下，如果某个broker上的队列越多，则该broker压力越大。】

RocketMQ的架构图:

- Broker:主要负责消息的存储、投递和查询以及服务高可用保证。【即消息队列服务器，生产者生产消息到Broker，消费者从Broker拉取消息并消费】
- NameServer:是一个注册中心，主要提供两个功能：Broker管理和路由信息管理。Broker会将自己的信息注册到NameServer中，此时NameServer就存放了很多Broker的信息（Broker的路由表），消费者和生产者就从NameServer中获取路由表然后照着路由表的信息和对应的Broker进行通信（生产者和消费者定期定向组查询相关的Broker的信息）。
- Producer：消息发布的角色，支持分布式集群方式部署。
- Consumer：消息消费的角色，支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。说白了就是消费者。

![image-20240402222239451](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240402222239451.png)

#### 2.RocketMQ功能特性

1.**普通消息**：一般应用于微服务解耦、事件驱动、数据集成等场景，这些场景大多数要求数据传输通道具有可靠传输的能力，且对消息的处理时机、处理顺序没有特别要求。

![image-20240403200212955](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403200212955.png)

**普通消息生命周期**：

- **初始化**：消息被生产者构建并完成初始化，待发送到服务端的状态。
- **待消费**：消息被发送到服务端，对消费者可见，等待消费者消费状态。
- **消费中**：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。此时服务端会等待消费者完成消费并提交消费结果，如果一定时间内没有收到消费者的响应，RocketMQ会对消息进行重试。
- **消费提交**：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。RocketMQ 默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。
- **消息删除**：RocketMQ按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。

**2.定时消息：**使用 RocketMQ 的定时消息可以简化定时调度任务的开发逻辑，实现高性能、可扩展、高可靠的定时触发能力。

基于定时消息的超时任务处理具备如下优势：

- **精度高、开发门槛低**：基于消息通知方式不存在定时阶梯间隔。可以轻松实现任意精度事件触发，无需业务去重。
- **高性能可扩展**：传统的数据库扫描方式较为复杂，需要频繁调用接口扫描，容易产生性能瓶颈。RocketMQ 的定时消息具有高并发和水平扩展的能力

![image-20240403200858388](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403200858388.png)

**定时消息生命周期：**

- **初始化**：消息被生产者构建并完成初始化，待发送到服务端的状态。
- **定时中**：消息被发送到服务端，和普通消息不同的是，服务端不会直接构建消息索引，而是会将定时消息**单独存储在定时存储系统中**，等待定时时刻到达。
- **待消费**：定时时刻到达后，服务端将消息重新写入普通存储引擎，对下游消费者可见，等待消费者消费的状态。
- **消费中**：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，RocketMQ 会对消息进行重试处理。
- **消费提交**：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。RocketMQ 默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。
- **消息删除**：Apache RocketMQ 按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。

【定时消息的实现逻辑需要先经过定时存储等待触发，定时时间到达后才会被投递给消费者。因此，如果将大量定时消息的定时时间设置为同一时刻，则到达该时刻后会有大量消息同时需要被处理，会造成系统压力过大，导致消息分发延，影响定时精度】

 **3.顺序消息**：顺序消息仅支持MessageType为FIFO的主题，即顺序消息只能发送至类型为顺序消息的主题中，发送的消息的类型必须和主题的类型一致。和普通消息发送相比，顺序消息发送必须要设置消息组。（推荐MessageQueueSelector 的方式）。要保证消息的顺序性需要单一生产者串行发送。

**单线程使用 MessageListenerConcurrently 可以顺序消费，多线程环境下使用 MessageListenerOrderly 才能顺序消费。**

**4.事务消息：**是 Apache RocketMQ 提供的一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性。简单来讲，就是将本地事务（数据库的 DML 操作）与发送消息合并在同一个事务中。例如，新增一个订单。在事务未提交之前，不发送订阅的消息。发送消息的动作随着事务的成功提交而发送，随着事务的回滚而取消。

**！！不建议单一进程创建大量生产者**

**！！不建议频繁创建和销毁生产者**

#### 3.消息者分类

1.**PushConsumer:**高度封装的消费类型，消费消息仅仅通过通过消费监听器监听并返回结果。 消息的获取、消费状态提交以及消费重试都通过 RocketMQ 的客户端 SDK 完成。

- **返回消费成功**：以 Java SDK 为例，返回，表示该消息处理成功，服务端按照消费结果更新消费进度。`ConsumeResult.SUCCESS`
- **返回消费失败**：以 Java SDK 为例，返回，表示该消息处理失败，需要根据消费重试逻辑判断是否进行重试消费。`ConsumeResult.FAILURE`
- **出现非预期失败**：例如抛异常等行为，该结果按照消费失败处理，需要根据消费重试逻辑判断是否进行重试消费。

使用 PushConsumer 消费者消费时，不允许使用以下方式处理消息，否则 RocketMQ 无法保证消息的可靠性。

- 错误方式一：消息还未处理完成，就提前返回消费成功结果。 此时如果消息消费失败，RocketMQ 服务端是无法感知的，因此不会进行消费重试。
- 错误方式二：在消费监听器内将消息再次分发到自定义的其他线程，消费监听器提前返回消费结果。 此时如果消息消费失败，RocketMQ 服务端同样无法感知，因此也不会进行消费重试。
- PushConsumer 严格限制了消息同步处理及每条消息的处理超时时间，适用于以下场景： 
  - 消息处理时间可预估：如果不确定消息处理耗时，经常有预期之外的长时间耗时的消息，PushConsumer 的可靠性保证会频繁触发消息重试机制造成大量重复消息。
  - 无异步化、高级定制场景：PushConsumer 限制了消费逻辑的线程模型，由客户端 SDK 内部按最大吞吐量触发消息处理。 该模型开发逻辑简单，但是不允许使用异步化和自定义处理流程。

**2.简单消费者：**SimpleConsumer 是一种接口原子型的消费者类型，消息的获取、消费状态提交以及消费重试都是通过消费者业务逻辑主动发起调用完成。

SimpleConsumer 适用于以下场景：

- 消息处理时长不可控：如果消息处理时长无法预估，经常有长时间耗时的消息处理情况。 建议使用 SimpleConsumer 消费类型，可以在消费时自定义消息的预估处理时长，若实际业务中预估的消息处理时长不符合预期，也可以通过接口提前修改。
- 需要异步化、批量消费等高级定制场景：SimpleConsumer 在 SDK 内部没有复杂的线程封装，完全由业务逻辑自由定制，可以实现异步分发、批量消费等高级定制场景。
- 需要自定义消费速率：SimpleConsumer 是由业务逻辑主动调用接口获取消息，因此可以自由调整获取消息的频率，自定义控制消费速率。

#### **4.消费者分组和生产者分组**

**生产者分组**：RocketMQ 服务端 5.x 版本开始，**生产者是匿名的**，无需管理生产者分组（ProducerGroup）。

**消费者分组：**是多个消费行为一致的消费者的负载均衡分组。 消费者分组不是具体实体而是一个逻辑资源。 通过消费者分组实现消费性能的水平扩展以及高可用容灾。

**消费者分组中的订阅关系、投递顺序、消费重试策略是一致的。**

- **订阅关系：**Apache RocketMQ 以消费者分组的粒度管理订阅关系，实现订阅关系的管理和追溯。
- **投递顺序性：**Apache RocketMQ 的服务端将消息投递给消费者消费时，支持顺序投递和并发投递，投递方式在消费者分组中统一配置。
- **消费重试策略**：消费者消费消息失败时的重试策略，包括重试次数、死信队列设置等。

**顺序消费`R**ocketMQ` 在主题上是无序的、它只有在队列层面才是保证有序** 的。

- 普通顺序：消费者通过 **同一个消费队列收到的消息是有顺序的** ，不同消息队列收到的消息则可能是无顺序的。 普通顺序消息在 **重启情况下不会保证消息顺序性** (短暂时间) 。
- 严格顺序：消费者收到的 **所有消息** 均是有顺序的。 严格顺序消息 **即使在异常情况下也会保证消息的顺序性** 

RocketMQ 实现了两种队列选择算法，也可以自己实现

- 轮询算法

  - 轮询算法就是向消息指定的 topic 所在队列中依次发送消息，保证消息均匀分布
  - 是 RocketMQ 默认队列选择算法

- 最小投递延迟算法

  - 每次消息投递的时候统计消息投递的延迟，选择队列时优先选择消息延时小的队列，导致消息分布不均匀,按照如下设置即可。

  - ```java
    producer.setSendLatencyFaultEnable(true);
    ```

- 继承 MessageQueueSelector 实现

**事务消息加上事务反查机制** 来解决分布式事务问题的。在第一步发送的 half 消息 ，它的意思是 **在事务提交之前，对于消费者来说，这个消息是不可见的** 

![image-20240403214954424](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403214954424.png)

**解决事务堆积**：当流量到峰值的时候是因为生产者生产太快，可以使用一些 **限流降级** 的方法，也可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。

![image-20240403215102447](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403215102447.png)

**回溯消费**是指 已经消费成功的消息，由于业务上需求需要重新消费，在 中， 在向 投递成功消息后，**消息仍然需要保留** 。 并且重新消费一般是按照时间维度。

#### 5.保证高性能读写

![image-20240403215203041](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403215203041.png)

**1.传统的 IO 读写**其实就是 read + write 的操作，整个过程会分为如下几步

- 用户调用 read()方法，开始读取数据，此时发生一次上下文从用户态到内核态的切换，也就是图示的切换 1
- 将磁盘数据通过 DMA 拷贝到内核缓存区
- 将内核缓存区的数据拷贝到用户缓冲区，这样用户，也就是我们写的代码就能拿到文件的数据
- read()方法返回，此时就会从内核态切换到用户态，也就是图示的切换 2
- 当我们拿到数据之后，就可以调用 write()方法，此时上下文会从用户态切换到内核态，即图示切换 3
- CPU 将用户缓冲区的数据拷贝到 Socket 缓冲区
- 将 Socket 缓冲区数据拷贝至网卡
- write()方法返回，上下文重新从内核态切换到用户态，即图示切换 4

**2.零拷贝技术：移动地图**mmap（memory map）是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。

简单地说就是内核缓冲区和应用缓冲区共享，从而减少了从读缓冲区到用户缓冲区的一次 CPU 拷贝。【基于 mmap IO 读写其实就变成 mmap + write 的操作，也就是用 mmap 替代传统 IO 中的 read 操作】

![image-20240403215310637](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403215310637.png)

**3.发送文件；**sendfile()跟 mmap()一样，也会减少一次 CPU 拷贝，但是它同时也会减少两次上下文切换。

![image-20240403215404774](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403215404774.png)

在同步刷盘中需要等待一个刷盘成功的  ，同步刷盘对  消息可靠性来说是一种不错的保障，但是 **性能上会有较大影响** ，一般地适用于金融等特定业务场景。`ACK``MQ`

而异步刷盘往往是开启一个线程去异步地执行刷盘操作。 消息刷盘采用后台异步线程提交的方式进行， **降低了读写延迟** ，提高了  的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。

一般地，**异步刷盘只有在 `Broker` 意外宕机的时候会丢失部分数据**

![image-20240403215441974](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403215441974.png)

上面的同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的  主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。`Borker`

- 同步复制：也叫 “同步双写”，也就是说，**只有消息同步双写到主从节点上时才返回写入成功** 。
- 异步复制：**消息写入主节点之后就直接返回写入成功** 。

```
RocketMQ` 采用的是 **混合型的存储结构** ，即为  单个实例下所有的队列共用一个日志数据文件来存储消息。 有意思的是在同样高并发的  中会为每个  分配一个存储文件。 这就有点类似于我们有一大堆书需要装上书架， 是不分书的种类直接成批的塞上去的，而  是将书本放入指定的分类区域的。`Broker``Kafka``Topic``RockeMQ``Kafka
```

![image-20240403215627627](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240403215627627.png)

### 五、RabbitMQ

RabbitMQ是一个在AMQP（Advanced Message Queuing Protocol)基础上实现的，可复用的企业消息系统。可以用于大型软件系统各个模块之间的高效通信、支持高并发、支持可扩展。

RabbitMQ 是使用 Erlang 编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正是如此，使的它变的非常重量级，更适合于企业级的开发。它同时实现了一个 Broker 构架，这意味着消息在发送给客户端时先在中心队列排队，对路由(Routing)、负载均衡(Load balance)或者数据持久化都有很好的支持。

#### 1.RabbitMQ特点

- **可靠性：**RabbitMQ使用一些机制来保证可靠性、如持久化、传输确认及发布确认。
- **灵活的路由：**在进入队列之前，通过交换器来路由信息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。
- **扩展性：**多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展集群中的节点。
- **高可用性：**队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。
- **多种协议：**除了支持原生AMQP，还支持STOMP、MQTT等多种消息中间件协议
- **多语言客户端：**几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。
- **管理界面：**提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。
- **插件机制：**提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。

#### 2.RabbitMQ核心概念

![image-20240404205036956](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240404205036956.png)

- Producer（生产者）：生产消息的一方
- Consumer（消费者）：消费消息的一方

消息一般由2部分组成：消息头和消息体。消息体也可以称为payLoad，消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key(路由键)，priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）。生产者把消息交由RabbitMQ后，RabbitMQ会根据消息头把消息发给感兴趣的消息者（Consumer）。

**Exchange(交换器)**：用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给 **Producer(生产者)** ，或许会被直接丢弃掉 。这里可以将 RabbitMQ 中的交换器看作一个简单的实体。

RabbitMQ 中，消息并不是直接被投递到 **Queue(消息队列)** 中的，中间还必须经过 **Exchange(交换器)** 这一层，**Exchange(交换器)** 会把我们的消息分配到对应的 **Queue(消息队列)** 中。Ra**bbitMQ 的 Exchange(交换器) 有 4 种类型，不同的类型对应着不同的路由策略**：**direct(默认)**，**fanout**, **topic**, 和 **headers**，不同类型的 Exchange 转发消息的策略有所区别。

![image-20240404210158707](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240404210158707.png)

生产者将消息发给交换器的时候，一般会指定一个**RoutingKey(路由键)**，用来指定这个消息的路由规则。而**这个RoutingKey需要与交换器类型和绑定键（BindingKey)联合使用才能最终生效**。

通过 **Binding(绑定)** 将 **Exchange(交换器)** 与 **Queue(消息队列)** 关联起来，在绑定的时候一般会指定一个 **BindingKey(绑定建)** ,这样 RabbitMQ 就知道如何正确将消息路由到队列了,如下图所示。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。Exchange 和 Queue 的绑定可以是多对多的关系。

![image-20240404210519800](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240404210519800.png)

生产者将消息发送给交换器时，需要一个 RoutingKey,当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。在绑定多个队列到同一个交换器的时候，这些绑定允许使用相同的 BindingKey。BindingKey 并不是在所有的情况下都生效，它依赖于交换器类型，比如 fanout 类型的交换器就会无视，而是将消息路由到所有绑定到该交换器的队列中。

**Queue（消息队列）用来保存消息直到发送给消费者**。它是消息的容器，也是信息的终点。一个消息可投入一个或多个队列。消息一直在队列里，等待消费者连接到这个队列将其取走。

RabbitMQ中消息只能存储在 **队列** 中，这一点和 **Kafka** 这种消息中间件相反。Kafka 将消息存储在 **topic（主题）** 这个逻辑层面，而相对应的队列逻辑只是 topic 实际存储文件中的位移标识。 RabbitMQ 的生产者生产消息并最终投递到队列中，消费者可以从队列中获取消息并消费。

**多个消费者可以订阅同一个队列**，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免消息被重复消费。**RabbitMQ** 不支持队列层面的广播消费,如果有广播消费的需求，需要在其上进行二次开发,这样会很麻烦，不建议这样做。

**Broker(消息中间件的服务节点)：一个RabbitMQ Broker可以看作一个RabbitMQ 服务节点，或者是RabbitMQ服务实例。**

![image-20240404210949019](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240404210949019.png)

**Exchange Types(交换器类型)**：**fanout**、**direct**、**topic**、**headers** 

1.**fanout:**路由规则简单，会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中，不需要做任何判断操作，所有是所有类型里面速度最快的，常用来广播消息。

2.**direct:**路由规则也很简单，会把消息路由到那些BindingKey与RountingKey完全匹配的Queue中，常用在处理有优先级的任务，根据任务的优先级把消息发送到对应的队列，这样可以指派更多的资源去处理高优先级资源。

![image-20240404211356666](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240404211356666.png)

3.**topic:**交换器在匹配规则上进行了扩展，它与 direct 类型的交换器相似，也是将消息路由到 BindingKey 和 RoutingKey 相匹配的队列中，但这里的匹配规则有些不同，它约定：

- RoutingKey 为一个点号“．”分隔的字符串（被点号“．”分隔开的每一段独立的字符串称为一个单词），如 “com.rabbitmq.client”、“java.util.concurrent”、“com.hidden.client”;
- BindingKey 和 RoutingKey 一样也是点号“．”分隔的字符串；
- BindingKey 中可以存在两种特殊字符串“*”和“#”，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词(可以是零个)。

![image-20240404211544321](C:\Users\Luckylemon\AppData\Roaming\Typora\typora-user-images\image-20240404211544321.png)

4.**headers(不推荐)：**交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的 headers 属性进行匹配。在绑定队列和交换器时指定一组键值对，当发送消息到交换器时，RabbitMQ 会获取到该消息的 headers（也是一个键值对的形式)，对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers 类型的交换器性能会很差，而且也不实用，基本上不会看到它的存在。

#### 3.AMQP是什么？

RabbitMQ就是 AMQP 协议的 `Erlang` 的实现(当然 RabbitMQ 还支持 `STOMP2`、 `MQTT3` 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。**RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。**

AMQP协议的三层：

- **Module Layer:**协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。
- **Session Layer:**中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。
- **TransportLayer:**最底层，主要传输二进制数据流，提供帧的处理、信道复用、错误检测和数据表示等。

AMQP模型的三大组件：

- **交换器：**消息代理服务器中用于把消息路由到队列的组件
- **队列：**用来存储消息的数据结构，位于硬盘或内存中
- **绑定：**一套规则，告知交换器消息应该将消息投递给哪个队列

#### 4.消费者和生产者

**生产者：**

- 消息生产者，就是投递消息的一方。
- 消息一般包含两个部分：消息体（`payload`)和标签(`Label`)。

**消费者**：

- 消费消息，也就是接收消息的一方。
- 消费者连接到 RabbitMQ 服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。

**Broker**：可以看做 RabbitMQ 的服务节点。一般情况下一个 Broker 可以看做一个 RabbitMQ 服务器。

**Queue**：RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。

**Exchange**：生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃

#### 5.死信队列

DLX（Dead-Letter-Exchange),死信交换器，死信邮箱。当消息在一个队列中变成死信之后，能被重新被发送到另一个交换器中，这个交换器就是DLX，绑定DLX的队列就是死信队列。

**导致死信的原因：**

- 消息被拒且requeue = false
- 消息TTL过期
- 队列满了，无法再添加

#### 6.延迟队列

延迟队列是指存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到。【AMQP 协议以及 RabbitMQ 本身没有直接支持延迟队列的功能，但是可以通过 TTL 和 DLX 模拟出延迟队列的功能】

**实现延迟消息的方式：**

1. 通过 RabbitMQ 本身队列的特性来实现，需要使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。
2. 在 RabbitMQ 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang/OPT 18.0 及以上。

#### 7.优先级队列

自 V3.5.0 有优先级队列实现，优先级高的队列会先被消费。

可以通过`x-max-priority`参数来实现优先级队列。不过，当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。

#### 8.RabbitMQ的工作模式

- 简单模式
- work 工作模式
- pub/sub 发布订阅模式
- Routing 路由模式
- Topic 主题模式

#### 9.RabbitMQ消息怎么传输？

由于 TCP 链接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈，所以 RabbitMQ 使用信道的方式来传输数据。信道（Channel）是生产者、消费者与 RabbitMQ 通信的渠道，信道是建立在 TCP 链接上的虚拟链接，且每条 TCP 链接上的信道数量没有限制。就是说 RabbitMQ 在一条 TCP 链接上建立成百上千个信道来达到多个线程处理，这个 TCP 被多个线程共享，每个信道在 RabbitMQ 都有唯一的 ID，保证了信道私有性，每个信道对应一个线程使用。

**保证消息的可靠性：**

**消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢**。

- 生产者到 RabbitMQ：事务机制和 Confirm 机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。
- RabbitMQ 自身：持久化、集群、普通模式、镜像模式。
- RabbitMQ 到消费者：basicAck 机制、死信队列、消息补偿机制。

**保证RabbitMQ消息的顺序性：**

- 拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；
- 或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

**保证RabbitMQ高可用：**

RabbitMQ是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

- **单机模式：**Demo级别的
- **普通集群模式：**
- 就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。
- **镜像集群模式：**才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。【好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据】

#### 10.解决消息队列的延时以及过期失效

可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导。

